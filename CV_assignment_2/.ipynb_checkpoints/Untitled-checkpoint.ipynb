{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import solution as sol\n",
    "from PIL import Image, ImageDraw\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "def RANSACFilter(\n",
    "        matched_pairs, keypoints1, keypoints2,\n",
    "        orient_agreement, scale_agreement):\n",
    "    \"\"\"\n",
    "    This function takes in `matched_pairs`, a list of matches in indices\n",
    "    and return a subset of the pairs using RANSAC.\n",
    "    Inputs:\n",
    "        matched_pairs: a list of tuples [(i, j)],\n",
    "            indicating keypoints1[i] is matched\n",
    "            with keypoints2[j]\n",
    "        keypoints1, 2: keypoints from image 1 and image 2\n",
    "            stored in np.array with shape (num_pts, 4)\n",
    "            each row: row, col, scale, orientation\n",
    "        *_agreement: thresholds for defining inliers, floats\n",
    "    Output:\n",
    "        largest_set: the largest consensus set in [(i, j)] format\n",
    "\n",
    "    HINTS: the \"*_agreement\" definitions are well-explained\n",
    "           in the assignment instructions.\n",
    "    \"\"\"\n",
    "    assert isinstance(matched_pairs, list)\n",
    "    assert isinstance(keypoints1, np.ndarray)\n",
    "    assert isinstance(keypoints2, np.ndarray)\n",
    "    assert isinstance(orient_agreement, float)\n",
    "    assert isinstance(scale_agreement, float)\n",
    "    ## START\n",
    "    ranint = random.radint(0,len(matched_pairs))\n",
    "    \n",
    "    largest_set = []\n",
    "    ranint = random.randint(0,len(matched_pairs)-1)\n",
    "    x1,y2 = matched_pairs[ranint]\n",
    "    radian1 = keypoints1[x1][3]+keypoints2[y2][3]\n",
    "    largest_set.append([x1,y2])\n",
    "    for i in range(0,10):\n",
    "        ranint = random.randint(0,len(matched_pairs)-1)\n",
    "        x,y = matched_pairs[ranint]\n",
    "        radian = keypoints1[x][3]+keypoints2[y][3]\n",
    "        diff = radian1 - radian\n",
    "        if math.cos(radian-radian1)<math.cos(orient_agreement):\n",
    "            largest_set.append((x,y))\n",
    "    ## END\n",
    "    assert isinstance(largest_set, list)\n",
    "    return largest_set\n",
    "\n",
    "#이녀석 첫번째\n",
    "def FindBestMatches(descriptors1, descriptors2, threshold):\n",
    "    \"\"\"\n",
    "    This function takes in descriptors of image 1 and image 2,\n",
    "    and find matches between them. See assignment instructions for details.\n",
    "    Inputs:\n",
    "        descriptors: a K-by-128 array, where each row gives a descriptor\n",
    "        for one of the K keypoints.  The descriptor is a 1D array of 128\n",
    "        values with unit length.\n",
    "        threshold: the threshold for the ratio test of \"the distance to the nearest\"\n",
    "                   divided by \"the distance to the second nearest neighbour\".\n",
    "                   pseudocode-wise: dist[best_idx]/dist[second_idx] <= threshold\n",
    "    Outputs:\n",
    "        matched_pairs: a list in the form [(i, j)] where i and j means\n",
    "                       descriptors1[i] is matched with descriptors2[j].\n",
    "    \"\"\"\n",
    "    assert isinstance(descriptors1, np.ndarray)\n",
    "    assert isinstance(descriptors2, np.ndarray)\n",
    "    assert isinstance(threshold, float)\n",
    "    ## START\n",
    "    ## the following is just a placeholder to show you the output format\n",
    "    shape1 = descriptors1.shape[0]\n",
    "    shape2 = descriptors2.shape[0]\n",
    "    match = {}\n",
    "    matched_pairs=[]\n",
    "    for i in range(shape1):\n",
    "        for j in range(shape2):\n",
    "            angle = math.acos(np.dot(descriptors1[i],descriptors2[j]))\n",
    "            match[angle] = i,j\n",
    "        match_list = sorted(match)\n",
    "        f_neigh = match_list[0]\n",
    "        s_neigh = match_list[1]\n",
    "        ratio = f_neigh/s_neigh\n",
    "        if ratio <= threshold:\n",
    "            key1,key2 = match[f_neigh]\n",
    "            matched_pairs.append([key1,key2])\n",
    "        match = {}\n",
    "#     distances = np.array(distances)\n",
    "#     distances = distances.reshape(shape1,shape2)\n",
    "#     indices1 = np.arange(descriptors1.shape[0])\n",
    "#     indices2 = np.argmin(distances, axis=1)\n",
    "#     best_distances = distances[indices1,indices2]\n",
    "#     distances[indices1, indices2] = np.inf\n",
    "#     second_best_indices2 = np.argmin(distances[indices1], axis=1)\n",
    "#     second_best_distances = distances[indices1, second_best_indices2]\n",
    "#     second_best_distances[second_best_distances == 0]=np.finfo(np.double).eps\n",
    "#     ratio = best_distances / second_best_distances\n",
    "#     mask = ratio < threshold\n",
    "#     for i,j in zip(indices1[mask],indices2[mask]):\n",
    "#        matched_pairs.append((i,j))\n",
    "    ## END\n",
    "    #matched_pairs=matched_pairs.tolist()\n",
    "    return matched_pairs\n",
    "\n",
    "\n",
    "def DisplayMatches(im1, im2, matched_pairs):\n",
    "    \"\"\"Display matches on a new image with the two input images placed side by side.\n",
    "\n",
    "    Arguments:\n",
    "     im1           1st image (in PIL 'RGB' format)\n",
    "     im2           2nd image (in PIL 'RGB' format)\n",
    "     matched_pairs list of matching keypoints, im1 to im2\n",
    "\n",
    "    Displays and returns a newly created image (in PIL 'RGB' format)\n",
    "    \"\"\"\n",
    "    im3 = AppendImages(im1,im2)\n",
    "    offset = im1.size[0]\n",
    "    draw = ImageDraw.Draw(im3)\n",
    "    for match in matched_pairs:\n",
    "        draw.line((match[0][1], match[0][0], offset+match[1][1], match[1][0]),fill=\"red\",width=2)\n",
    "    im3.show()\n",
    "    return im3\n",
    "def Match(image1, image2, ratio_thres):\n",
    "    \"\"\"\n",
    "    Read two images and their associated SIFT keypoints and descriptors.\n",
    "    Find matches between images based on acos distance.\n",
    "    Display the final matches.\n",
    "    HINT: See main_match.py on how to use this function.\n",
    "    \"\"\"\n",
    "    im1, keypoints1, descriptors1 = ReadKeys(image1)\n",
    "    im2, keypoints2, descriptors2 = ReadKeys(image2)\n",
    "\n",
    "    matched_pairs = FindBestMatches(\n",
    "        descriptors1, descriptors2, ratio_thres)\n",
    "    matched_pairs = [\n",
    "        [keypoints1[i], keypoints2[j]] for (i, j) in matched_pairs]\n",
    "    assert len(matched_pairs) > 0, \"No match received\"\n",
    "    \n",
    "    im3 = DisplayMatches(im1, im2, matched_pairs)\n",
    "    return im3\n",
    "def AppendImages(im1, im2):\n",
    "    \"\"\"Create a new image that appends two images side-by-side.\n",
    "\n",
    "    The arguments, im1 and im2, are PIL images of type RGB\n",
    "    \"\"\"\n",
    "    im1cols, im1rows = im1.size\n",
    "    im2cols, im2rows = im2.size\n",
    "    im3 = Image.new('RGB', (im1cols+im2cols, max(im1rows,im2rows)))\n",
    "    im3.paste(im1,(0,0))\n",
    "    im3.paste(im2,(im1cols,0))\n",
    "    return im3\n",
    "\n",
    "def ReadKeys(image):\n",
    "    \"\"\"Input an image and its associated SIFT keypoints.\n",
    "\n",
    "    The argument image is the image file name (without an extension).\n",
    "    The image is read from the PGM format file image.pgm and the\n",
    "    keypoints are read from the file image.key.\n",
    "\n",
    "    ReadKeys returns the following 3 arguments:\n",
    "\n",
    "    image: the image (in PIL 'RGB' format)\n",
    "\n",
    "    keypoints: K-by-4 array, in which each row has the 4 values specifying\n",
    "    a keypoint (row, column, scale, orientation).  The orientation\n",
    "    is in the range [-PI, PI] radians.\n",
    "\n",
    "    descriptors: a K-by-128 array, where each row gives a descriptor\n",
    "    for one of the K keypoints.  The descriptor is a 1D array of 128\n",
    "    values with unit length.\n",
    "    \"\"\"\n",
    "    im = Image.open(image+'.pgm').convert('RGB')\n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    first = True\n",
    "    with open(image+'.key','r') as f:\n",
    "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONNUMERIC,skipinitialspace = True)\n",
    "        descriptor = []\n",
    "        for row in reader:\n",
    "            if len(row) == 2:\n",
    "                assert first, \"Invalid keypoint file header.\"\n",
    "                assert row[1] == 128, \"Invalid keypoint descriptor length in header (should be 128).\"\n",
    "                count = row[0]\n",
    "                first = False\n",
    "            if len(row) == 4:\n",
    "                keypoints.append(np.array(row))\n",
    "            if len(row) == 20:\n",
    "                descriptor += row\n",
    "            if len(row) == 8:\n",
    "                descriptor += row\n",
    "                assert len(descriptor) == 128, \"Keypoint descriptor length invalid (should be 128).\"\n",
    "                #normalize the key to unit length\n",
    "                descriptor = np.array(descriptor)\n",
    "                descriptor = descriptor / math.sqrt(np.sum(np.power(descriptor,2)))\n",
    "                descriptors.append(descriptor)\n",
    "                descriptor = []\n",
    "    assert len(keypoints) == count, \"Incorrect total number of keypoints read.\"\n",
    "    print(\"Number of keypoints read:\", int(count))\n",
    "    descriptors = np.stack(descriptors, axis=0)\n",
    "    return [im,keypoints,descriptors]\n",
    "\n",
    "def FindBestMatchesRANSAC(\n",
    "        keypoints1, keypoints2,\n",
    "        descriptors1, descriptors2, threshold,\n",
    "        orient_agreement, scale_agreement):\n",
    "    \"\"\"\n",
    "    Note: you do not need to change this function.\n",
    "    However, we recommend you to study this function carefully\n",
    "    to understand how each component interacts with each other.\n",
    "\n",
    "    This function find the best matches between two images using RANSAC.\n",
    "    Inputs:\n",
    "        keypoints1, 2: keypoints from image 1 and image 2\n",
    "            stored in np.array with shape (num_pts, 4)\n",
    "            each row: row, col, scale, orientation\n",
    "        descriptors1, 2: a K-by-128 array, where each row gives a descriptor\n",
    "        for one of the K keypoints.  The descriptor is a 1D array of 128\n",
    "        values with unit length.\n",
    "        threshold: the threshold for the ratio test of \"the distance to the nearest\"\n",
    "                   divided by \"the distance to the second nearest neighbour\".\n",
    "                   pseudocode-wise: dist[best_idx]/dist[second_idx] <= threshold\n",
    "        orient_agreement: in degrees, say 30 degrees.\n",
    "        scale_agreement: in floating points, say 0.5\n",
    "    Outputs:\n",
    "        matched_pairs_ransac: a list in the form [(i, j)] where i and j means\n",
    "        descriptors1[i] is matched with descriptors2[j].\n",
    "    Detailed instructions are on the assignment website\n",
    "    \"\"\"\n",
    "    orient_agreement = float(orient_agreement)\n",
    "    assert isinstance(keypoints1, np.ndarray)\n",
    "    assert isinstance(keypoints2, np.ndarray)\n",
    "    assert isinstance(descriptors1, np.ndarray)\n",
    "    assert isinstance(descriptors2, np.ndarray)\n",
    "    assert isinstance(threshold, float)\n",
    "    assert isinstance(orient_agreement, float)\n",
    "    assert isinstance(scale_agreement, float)\n",
    "    matched_pairs = FindBestMatches(\n",
    "        descriptors1, descriptors2, threshold)\n",
    "    matched_pairs_ransac = RANSACFilter(\n",
    "        matched_pairs, keypoints1, keypoints2,\n",
    "        orient_agreement, scale_agreement)\n",
    "    return matched_pairs_ransac\n",
    "def MatchRANSAC(\n",
    "        image1, image2, ratio_thres, orient_agreement, scale_agreement):\n",
    "    \"\"\"\n",
    "    Read two images and their associated SIFT keypoints and descriptors.\n",
    "    Find matches between images based on acos distance.\n",
    "    Filter a subset of matches using RANSAC\n",
    "    Display the final matches.\n",
    "    HINT: See main_match.py on how to use this function.\n",
    "    \"\"\"\n",
    "    im1, keypoints1, descriptors1 = ReadKeys(image1)\n",
    "    im2, keypoints2, descriptors2 = ReadKeys(image2)\n",
    "\n",
    "    keypoints1 = np.stack(keypoints1, axis=0)\n",
    "    keypoints2 = np.stack(keypoints2, axis=0)\n",
    "    matched_pairs = sol.FindBestMatchesRANSAC(\n",
    "        keypoints1, keypoints2,\n",
    "        descriptors1, descriptors2,\n",
    "        ratio_thres, orient_agreement, scale_agreement)\n",
    "    matched_pairs = [\n",
    "        [keypoints1[i], keypoints2[j]] for (i, j) in matched_pairs]\n",
    "    assert len(matched_pairs) > 0, \"No match received\"\n",
    "    im3 = DisplayMatches(im1, im2, matched_pairs)\n",
    "    return im3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hw_utils as util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keypoints read: 694\n",
      "Number of keypoints read: 579\n"
     ]
    }
   ],
   "source": [
    "im1, keypoints1, descriptors1 = ReadKeys('./data/scene')\n",
    "im2, keypoints2, descriptors2 = ReadKeys('./data/basmati')\n",
    "matched_pairs =  FindBestMatches(descriptors1,descriptors2,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keypoints read: 694\n",
      "Number of keypoints read: 579\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-834d4dcc2e13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m im = MatchRANSAC(\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m'./data/scene'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./data/basmati'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     ratio_thres=0.6, orient_agreement=30, scale_agreement=0.5)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MatchRANSAC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-147-b7538e1cfde7>\u001b[0m in \u001b[0;36mMatchRANSAC\u001b[1;34m(image1, image2, ratio_thres, orient_agreement, scale_agreement)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mkeypoints1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeypoints2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mdescriptors1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescriptors2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         ratio_thres, orient_agreement, scale_agreement)\n\u001b[0m\u001b[0;32m    268\u001b[0m     matched_pairs = [\n\u001b[0;32m    269\u001b[0m         [keypoints1[i], keypoints2[j]] for (i, j) in matched_pairs]\n",
      "\u001b[1;32m~\\workspace\\assignment\\CV_assignment_2\\solution.py\u001b[0m in \u001b[0;36mFindBestMatchesRANSAC\u001b[1;34m(keypoints1, keypoints2, descriptors1, descriptors2, threshold, orient_agreement, scale_agreement)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \"\"\"\n\u001b[0;32m    187\u001b[0m     \u001b[0morient_agreement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient_agreement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeypoints1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeypoints2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescriptors1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\workspace\\assignment\\CV_assignment_2\\solution.py\u001b[0m in \u001b[0;36mRANSACFilter\u001b[1;34m(matched_pairs, keypoints1, keypoints2, orient_agreement, scale_agreement)\u001b[0m\n\u001b[0;32m     25\u001b[0m            \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0minstructions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \"\"\"\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatched_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeypoints1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeypoints2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "im = MatchRANSAC(\n",
    "    './data/scene', './data/basmati',\n",
    "    ratio_thres=0.6, orient_agreement=30, scale_agreement=0.5)\n",
    "plt.title('MatchRANSAC')\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keypoints read: 694\n",
      "Number of keypoints read: 579\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f_meigh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-1ae6236afd7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test run matching with no ransac\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mMatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/scene'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./data/basmati'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio_thres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Match'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-150-bf83d98d87bb>\u001b[0m in \u001b[0;36mMatch\u001b[1;34m(image1, image2, ratio_thres)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     matched_pairs = FindBestMatches(\n\u001b[1;32m--> 141\u001b[1;33m         descriptors1, descriptors2, ratio_thres)\n\u001b[0m\u001b[0;32m    142\u001b[0m     matched_pairs = [\n\u001b[0;32m    143\u001b[0m         [keypoints1[i], keypoints2[j]] for (i, j) in matched_pairs]\n",
      "\u001b[1;32m<ipython-input-150-bf83d98d87bb>\u001b[0m in \u001b[0;36mFindBestMatches\u001b[1;34m(descriptors1, descriptors2, threshold)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_neigh\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0ms_neigh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mkey1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf_meigh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[0mmatched_pairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f_meigh' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Test run matching with no ransac\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    im =Match('./data/scene', './data/basmati', ratio_thres=0.6)\n",
    "    plt.title('Match')\n",
    "    plt.imshow(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.6\n",
    "shape1 = descriptors1.shape[0]\n",
    "shape2 = descriptors2.shape[0]\n",
    "distances = []\n",
    "matched_pairs=[]\n",
    "for i in range(shape1):\n",
    "    for j in range(shape2):\n",
    "        distances.append(math.acos(sum(descriptors1[i]*descriptors2[j])))\n",
    "distances = np.array(distances)\n",
    "distances = distances.reshape(shape1,shape2)\n",
    "indices1 = np.arange(descriptors1.shape[0])\n",
    "indices2 = np.argmin(distances, axis=1)\n",
    "best_distances = distances[indices1,indices2]\n",
    "distances[indices1, indices2] = np.inf\n",
    "second_best_indices2 = np.argmin(distances[indices1], axis=1)\n",
    "second_best_distances = distances[indices1, second_best_indices2]\n",
    "second_best_distances[second_best_distances == 0]=np.finfo(np.double).eps\n",
    "ratio = best_distances / second_best_distances\n",
    "mask = ratio < threshold\n",
    "for i,j in zip(indices1[mask],indices2[mask]):\n",
    "    matched_pairs.append([i,j])\n",
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[105, 7],\n",
       " [184, 15],\n",
       " [349, 28],\n",
       " [361, 71],\n",
       " [429, 37],\n",
       " [432, 30],\n",
       " [465, 42],\n",
       " [468, 77],\n",
       " [469, 78],\n",
       " [478, 71],\n",
       " [564, 51],\n",
       " [565, 56],\n",
       " [570, 110],\n",
       " [574, 96],\n",
       " [607, 80],\n",
       " [617, 57],\n",
       " [618, 58],\n",
       " [637, 104]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
